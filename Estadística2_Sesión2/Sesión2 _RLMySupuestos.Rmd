---
title: "Sesión 2. RLM y Supuestos"
author: "Curso: Estadística para el análisis político 2"
date: "Ciclo 2023-1"
output:
  prettydoc::html_pretty:
    theme: cayman
    highlight: github
---

<br>

<center><img src=" " width="200"/></center>

```{r,echo=FALSE, out.width="30%",fig.align="center"}
knitr::include_graphics("logoPUCP.png") 
```

## Regresión Lineal

LCF: ESTUDIAR LA DATA😎

```{r}


library(emo)
emo::ji('turtle')
```

Consider the emoji: **lion face, cat, fox face, owl, elephant, sad face**. I use these symbols in teaching documents to flag a sentence, paragraph, table or graph as say, <u>something of major importance</u> (lion face 🦁), <u>question to answer</u> (cat 🐈), <u>suggestion, hint or tip</u> (fox face 🦊), <u>statistical wisdom</u> (owl 🦉), <u>coding conventions & naming</u> (elephant 🐘) and <u>warning or error</u> (sad face 😟). <br><br>

### Ejemplo 1: Prediciendo los casos de COVID-19

Obtenemos nuestra base de datos:

```{r}
library(rio)
competitividad=import("COVID_COMPETITIVIDAD.sav")
names(competitividad)
```

### RECORDANDO LA REGRESIÓN LINEAL

Calcularemos un modelo para *predecir los casos de COVID-19 a partir del gasto real por hogar mensual*🥶

Variable dependiente: Casos COVID-19 por cada 100 mil personas (casos_100k)

Variable independiente: gasto real por hogar mensual (var5)

```{r}
modelo <- lm(competitividad$casos_100k ~ competitividad$var5)
summary(modelo)
```

Seguimos nuestro flujograma para evaluar el modelo:

1.  Nos preguntamos si el modelo es válido
2.  Qué tanto explica el modelo:
3.  Si la variable independiente aporta al modelo
4.  Identificamos los coeficientes

¿Qué sucede si ahora agregamos más variables?

#insertamos meme

Calculamos nuestro modelo, en este caso usaremos lo siguiente:

Variable dependiente: Casos COVID-19 por cada 100 mil personas Variables independientes: Stock de capital por trabajador (var3) + gasto real por hogar mensual (var5) + morbilidad (var20).

```{r}
modelo1 <- lm(competitividad$casos_100k~ competitividad$var3+competitividad$var5+
               competitividad$var20)
#otra forma de usar la función lm (usando menos símbolos de $), sería la siguiente:
#modelo1 <- lm(casos_100k~ var3+var5+var20, competitividad)
summary(modelo1)
```

Seguimos nuestro flujograma para evaluar el modelo:

1.  Nos preguntamos si el modelo es válido:

-   Si el p-value es menor a 0.05 significa que rechazamos la hipótesis nula, lo cual probaría que nuestro modelo sí funciona.

-Al tener un p-value de 1.185e-05 nuestro modelo sí funciona.

2.  ¿Qué tanto explica el modelo? -Revisamos el R cuadrado ajustado que va de 0 a 1 (0% a 100%)

-En este caso mis variables (en conjunto) explican el 68.9% de la variabilidad de mi dependiente, esto es bueno, pero quizá podría ser mejor.

3.  ¿Las variables independientes aportan al modelo? -Nos enfocamos en el p-value de cada independiente

-corroboramos que estas rechazen la hipótesis nula, es decir que sean menores que 0.05.

4.  Identificamos los coeficientes -En este caso hacemos uso del código modelo1\$coefficients.

-Armamos nuestra ecuación: y=1810.55+ var3\*(0.02382484)+ var5(1.48405800) + var20(-36.78156990)

#install.packages("lm.beta")

```{r}
library(lm.beta)
modelo1$coefficients

```

### SUPUESTOS

### 1- Linealidad (el problema es la no linealidad)

**Descrición** Como su nombre lo dice, debe de existir una linealidad entre la variable independiente y dependiente, en otras palabras,la linealidad indica que el valor esperado de la variable dependiente es una función lineal de cada variable independiente, manteniendo las demás fijas. La pendiente de esa línea no depende de los valores de las otras variables, por ello también nos fijamos variable por variable. Los efectos de diferentes variables independientes sobre el valor esperado de la variable dependiente son aditivos. Si este supuesto no se cumple significaría que posiblemente existan variables que no aporten al modelo o que se trate de una relación no lineal.

**Cómo detectarlo**

OPCIÓN 1: Exploración gráfica: Plot de valores residuales frente a valores predichos.

OPCIÓN 2: Calculando la correlación bivariada de cada independiente con la dependiente.

**Código e interpretación**

```{r}
library(ggfortify)
#Exploración gráfica
plot(modelo1,1)
autoplot(modelo1,1)
```

Usando el código plot, la línea roja debería de estar lo más cercana a la línea punteada. De acuerdo al resultado, el gráfico aún nos generaría suspicacias. En tanto, dado que la línea roja obedece a los puntos, éstos deberían distribuirse alrededor de una línea horizontal, con una varianza aproximadamente constante.

Si usamos la correlación, entonces revisamos cada una de las variables: -Nos fijamos en el p-value -Nos fijamos en el cor

```{r}
#Usando el test
cor.test(competitividad$casos_100k, competitividad$var3)
cor.test(competitividad$casos_100k, competitividad$var5)
cor.test(competitividad$casos_100k, competitividad$var20)
```

Al revisar todas las variables nos damos cuenta que todas tienen un p-value menor a 0.05, lo cual nos da a conocer que sí existe relación lineal.Sin embargo, si tuviese que sacar una variable, podría ser la var20, que a pesar de que sí cumple con un p-value menor que 0.05 (se rechaza la hipótesis nula), de todas las variables es la más cercana a "no cumplir".

También lo puedes graficar para que te de una idea de forma más rápida:

#install.packages("corrplot")

```{r}
library(corrplot)
#La funci?n cor calcula la matriz de correlaciones
M<-cor(competitividad[,c(3,11,13,28)],method="pearson")
corrplot(M, method="circle",type="upper")
corrplot(M, method="number")
corrplot.mixed(M)
```

### 2. Normalidad de residuos (el problema es la NO normalidad)

**Descrición**

Identificar si los errores siguen una distribución normal. La resta del valor observado menos el valor pronosticado (residuos) siguen una distribución normal, esto es importante porque si es que no se cumple no se podrían aplicar las pruebas globales del modelo.

**Cómo detectarlo**

Exploración gráfica: QQ plot de residuos Pruebas de normalidad a los residuos. Normalmente bastaría con la prueba de Shapiro Wilk, pero también se pueden probar otros como Lillieford, Kolmogorov (no es muy exigente), entre otros.

**Código e interpretación**

Si usamos sólo gráfico

```{r}
plot(modelo1, 2) #o también se puede usar el código autoplot(modelo1,2), las dos indicarían lo mismo.
```

```{r}
library(ggfortify)
autoplot(modelo1,2)
```

Todos los puntos deben estar sobre la diagonal. Los dos gráficos no son concluyentes, entonces procedo a realizar el test.

Si usamos prueba de normalidad:aplicamos la prueba de Shapiro a los residuos del modelo

```{r}
shapiro.test(modelo1$resid)
```

Ojo con la hipótesis nula. H0: Es normal (distribución normal) \| Ha: No es normal (no hay distribución normal)

Si el pvalor es menor a 0.05 entonces NO existe normalidad de residuos (problemas!), se rechazaría la distribución normal. Dado que nuestro p-value es 0.6006, mayor que 0.05, entonces sí estamos frente a un caso de distribució normal de los residuos.

### 3- Homocedasticidad (el problema es la heterocedasticidad)

**Descrición**

La homocedasticidad (también conocido como homogeneidad en la varianza de los residuos) indica que las variancias de los errores son constantes. Cuando no se cumple es un problema porque los estimadores no son consistentes ni eficientes y se presenta el caso de la heterocedasticidad.

**Cómo detectarlo**

OPCIÓN 1: Exploración gráfica: diagrama de residuos standarizados y valores predichos.

OPCIÓN 2: Con el Score Test for Non-Constant Error Variance, también llamado Test Breusch Pagan. Evalúa si la varianza del error cambia con el nivel de la variable respuesta (valores ajustados) o con una combinación lineal de predictores.

**Código e interpretación**

Si usamos el gráfico

```{r}
plot(modelo1, 3)
```

En el Gráfico la línea roja debe seguir una tendencia horizontal, esto representaría que la distribución de los puntos son uniformes. Al ver nuestro gráfico nos damos cuenta que la línea roja va hacia arriba, lo cual nos dice que el gráfico no es concluyente aún. Vamos al test.

Si usamos el test de BP:

```{r message=FALSE, warning=FALSE}
library(lmtest)
bptest(modelo1)
```

H0: El modelo es homocedástico Ha: El modelo es heterocedástico

Si el pvalor es menor a 0.05 entonces el modelo es heterocedástico (problema!). Esta vez estamos frente a un modelo homocedástico

### 4. Ausencia de multicolinealidad (el problema es la presencia de multicolinealidad)

**Descripción**

Se aplica en la regresión lineal MÚLTIPLE. Significa que las variables explicativas están relacionadas linealmente entre sí. La multicolinealidad hace que los coeficientes del modelo se vuelvan inestables, es decir, oscilarán violentamente ante cambios mínimos en las variables de insumo. Esto entendería que existe una relación fuerte entre variables independientes, por lo tanto podría darnos un modelo inestable.

**Cómo detectarlo**

Con el Factor de Inflación de Varianza (VIF). los factores de inflación de varianza deben de ser menores de 5. De acuerdo a nuestros resultados no encontramos multicolinealidad.

**Código e interpretación**

```{r}
library(DescTools)
VIF(modelo1)
```

Valores \> 5 indican presencia de multicolinealidad.

### 5.- Independencia de residuos (el problema es que existe autocorrelación en los residuos)

**Descripción**

Si los errores residuales **no son independientes**, es probable que demuestren algún tipo de patrón (que no siempre es obvio a simple vista).

**Cómo detectarlo**

Se puede realizar el Test de Durbin Watson (que mide el la presencia de correlación de cada error residual con el error residual "anterior")

**Código e interpretación**

```{r message=FALSE, warning=FALSE}
#Default
library(car)
durbinWatsonTest(modelo1)
```

Durbin Watson: Las hipótesis son: H0: Los residuos son independientes Ha: Los residuos no son independientes Si el pvalor es menor a 0.05 entonces los residuos no son independientes o también se podría decir que están **autocorrelacionados** (problema!). En este caso tenemos un p value de 0.518, mayor a 0.05, el cual nos indica que no nos encontramos frente a un caso de autocorrelación.

**Modelo 2** ¿Es posible mejorar mi modelo1? Esta vez, realizamos una regresión sin nuestra var20.

```{r}
modelo2 <- lm(casos_100k~ var3+var5, competitividad)
summary(modelo2)
```

Seguimos nuestro flujograma para evaluar el modelo:

1.  Nos preguntamos si el modelo es válido:

-   Si el p-value es menor a 0.05 significa que rechazamos la hipótesis nula, lo cual probaría que nuestro modelo sí funciona. -Al tener un p-value de 2.62e-05 nuestro modelo sí funciona.

2.  ¿Qué tanto explica el modelo? -Revisamos el R cuadrado ajustado que va de 0 a 1 (0% a 100%) -En este caso mis variables (en conjunto) explican el 61.7% de la variabilidad de mi dependiente, esto es bueno, pero quizá podría ser mejor.
3.  ¿Las variables independientes aportan al modelo? -Nos enfocamos en el p-value de cada independiente -corroboramos que estas rechazen la hipótesis nula, es decir que sean menores que 0.05.

Conclusiones preliminares: el modelo sí pasa la evaluación; mis variables siguen aportando al modelo, mi modelo es válido al tener un p value de 2.62e-05; sin embargo, al sacar la variable var20 nos damos cuenta que mi modelo2 explica menos que mi modelo1. Por lo tanto, solo al evaluar mi modelo2, a pesar de que es un modelo válido, optaría por mantener mi modelo1. Ojo, solo basándome en esta primera evaluación del modelo. Una decisión más fina sería al realizar mis pruebas de supuestos completa.
