---
title: "Sesi칩n 2. RLM y Supuestos"
author: "Curso: Estad칤stica para el an치lisis pol칤tico 2"
date: "Ciclo 2023-1"
output:
  prettydoc::html_pretty:
    theme: cayman
    highlight: github
---

<br>

<center><img src=" " width="200"/></center>

```{r,echo=FALSE, out.width="30%",fig.align="center"}
knitr::include_graphics("logoPUCP.png") 
```

## Regresi칩n Lineal

LCF: ESTUDIAR LA DATA游땙

```{r}


library(emo)
emo::ji('turtle')
```

Consider the emoji: **lion face, cat, fox face, owl, elephant, sad face**. I use these symbols in teaching documents to flag a sentence, paragraph, table or graph as say, <u>something of major importance</u> (lion face 游부), <u>question to answer</u> (cat 游낻), <u>suggestion, hint or tip</u> (fox face 游붉), <u>statistical wisdom</u> (owl 游불), <u>coding conventions & naming</u> (elephant 游냊) and <u>warning or error</u> (sad face 游). <br><br>

### Ejemplo 1: Prediciendo los casos de COVID-19

Obtenemos nuestra base de datos:

```{r}
library(rio)
competitividad=import("COVID_COMPETITIVIDAD.sav")
names(competitividad)
```

### RECORDANDO LA REGRESI칍N LINEAL

Calcularemos un modelo para *predecir los casos de COVID-19 a partir del gasto real por hogar mensual*游봈

Variable dependiente: Casos COVID-19 por cada 100 mil personas (casos_100k)

Variable independiente: gasto real por hogar mensual (var5)

```{r}
modelo <- lm(competitividad$casos_100k ~ competitividad$var5)
summary(modelo)
```

Seguimos nuestro flujograma para evaluar el modelo:

1.  Nos preguntamos si el modelo es v치lido
2.  Qu칠 tanto explica el modelo:
3.  Si la variable independiente aporta al modelo
4.  Identificamos los coeficientes

쯈u칠 sucede si ahora agregamos m치s variables?

#insertamos meme

Calculamos nuestro modelo, en este caso usaremos lo siguiente:

Variable dependiente: Casos COVID-19 por cada 100 mil personas Variables independientes: Stock de capital por trabajador (var3) + gasto real por hogar mensual (var5) + morbilidad (var20).

```{r}
modelo1 <- lm(competitividad$casos_100k~ competitividad$var3+competitividad$var5+
               competitividad$var20)
#otra forma de usar la funci칩n lm (usando menos s칤mbolos de $), ser칤a la siguiente:
#modelo1 <- lm(casos_100k~ var3+var5+var20, competitividad)
summary(modelo1)
```

Seguimos nuestro flujograma para evaluar el modelo:

1.  Nos preguntamos si el modelo es v치lido:

-   Si el p-value es menor a 0.05 significa que rechazamos la hip칩tesis nula, lo cual probar칤a que nuestro modelo s칤 funciona.

-Al tener un p-value de 1.185e-05 nuestro modelo s칤 funciona.

2.  쯈u칠 tanto explica el modelo? -Revisamos el R cuadrado ajustado que va de 0 a 1 (0% a 100%)

-En este caso mis variables (en conjunto) explican el 68.9% de la variabilidad de mi dependiente, esto es bueno, pero quiz치 podr칤a ser mejor.

3.  쯃as variables independientes aportan al modelo? -Nos enfocamos en el p-value de cada independiente

-corroboramos que estas rechazen la hip칩tesis nula, es decir que sean menores que 0.05.

4.  Identificamos los coeficientes -En este caso hacemos uso del c칩digo modelo1\$coefficients.

-Armamos nuestra ecuaci칩n: y=1810.55+ var3\*(0.02382484)+ var5(1.48405800) + var20(-36.78156990)

#install.packages("lm.beta")

```{r}
library(lm.beta)
modelo1$coefficients

```

### SUPUESTOS

### 1- Linealidad (el problema es la no linealidad)

**Descrici칩n** Como su nombre lo dice, debe de existir una linealidad entre la variable independiente y dependiente, en otras palabras,la linealidad indica que el valor esperado de la variable dependiente es una funci칩n lineal de cada variable independiente, manteniendo las dem치s fijas. La pendiente de esa l칤nea no depende de los valores de las otras variables, por ello tambi칠n nos fijamos variable por variable. Los efectos de diferentes variables independientes sobre el valor esperado de la variable dependiente son aditivos. Si este supuesto no se cumple significar칤a que posiblemente existan variables que no aporten al modelo o que se trate de una relaci칩n no lineal.

**C칩mo detectarlo**

OPCI칍N 1: Exploraci칩n gr치fica: Plot de valores residuales frente a valores predichos.

OPCI칍N 2: Calculando la correlaci칩n bivariada de cada independiente con la dependiente.

**C칩digo e interpretaci칩n**

```{r}
library(ggfortify)
#Exploraci칩n gr치fica
plot(modelo1,1)
autoplot(modelo1,1)
```

Usando el c칩digo plot, la l칤nea roja deber칤a de estar lo m치s cercana a la l칤nea punteada. De acuerdo al resultado, el gr치fico a칰n nos generar칤a suspicacias. En tanto, dado que la l칤nea roja obedece a los puntos, 칠stos deber칤an distribuirse alrededor de una l칤nea horizontal, con una varianza aproximadamente constante.

Si usamos la correlaci칩n, entonces revisamos cada una de las variables: -Nos fijamos en el p-value -Nos fijamos en el cor

```{r}
#Usando el test
cor.test(competitividad$casos_100k, competitividad$var3)
cor.test(competitividad$casos_100k, competitividad$var5)
cor.test(competitividad$casos_100k, competitividad$var20)
```

Al revisar todas las variables nos damos cuenta que todas tienen un p-value menor a 0.05, lo cual nos da a conocer que s칤 existe relaci칩n lineal.Sin embargo, si tuviese que sacar una variable, podr칤a ser la var20, que a pesar de que s칤 cumple con un p-value menor que 0.05 (se rechaza la hip칩tesis nula), de todas las variables es la m치s cercana a "no cumplir".

Tambi칠n lo puedes graficar para que te de una idea de forma m치s r치pida:

#install.packages("corrplot")

```{r}
library(corrplot)
#La funci?n cor calcula la matriz de correlaciones
M<-cor(competitividad[,c(3,11,13,28)],method="pearson")
corrplot(M, method="circle",type="upper")
corrplot(M, method="number")
corrplot.mixed(M)
```

### 2. Normalidad de residuos (el problema es la NO normalidad)

**Descrici칩n**

Identificar si los errores siguen una distribuci칩n normal. La resta del valor observado menos el valor pronosticado (residuos) siguen una distribuci칩n normal, esto es importante porque si es que no se cumple no se podr칤an aplicar las pruebas globales del modelo.

**C칩mo detectarlo**

Exploraci칩n gr치fica: QQ plot de residuos Pruebas de normalidad a los residuos. Normalmente bastar칤a con la prueba de Shapiro Wilk, pero tambi칠n se pueden probar otros como Lillieford, Kolmogorov (no es muy exigente), entre otros.

**C칩digo e interpretaci칩n**

Si usamos s칩lo gr치fico

```{r}
plot(modelo1, 2) #o tambi칠n se puede usar el c칩digo autoplot(modelo1,2), las dos indicar칤an lo mismo.
```

```{r}
library(ggfortify)
autoplot(modelo1,2)
```

Todos los puntos deben estar sobre la diagonal. Los dos gr치ficos no son concluyentes, entonces procedo a realizar el test.

Si usamos prueba de normalidad:aplicamos la prueba de Shapiro a los residuos del modelo

```{r}
shapiro.test(modelo1$resid)
```

Ojo con la hip칩tesis nula. H0: Es normal (distribuci칩n normal) \| Ha: No es normal (no hay distribuci칩n normal)

Si el pvalor es menor a 0.05 entonces NO existe normalidad de residuos (problemas!), se rechazar칤a la distribuci칩n normal. Dado que nuestro p-value es 0.6006, mayor que 0.05, entonces s칤 estamos frente a un caso de distribuci칩 normal de los residuos.

### 3- Homocedasticidad (el problema es la heterocedasticidad)

**Descrici칩n**

La homocedasticidad (tambi칠n conocido como homogeneidad en la varianza de los residuos) indica que las variancias de los errores son constantes. Cuando no se cumple es un problema porque los estimadores no son consistentes ni eficientes y se presenta el caso de la heterocedasticidad.

**C칩mo detectarlo**

OPCI칍N 1: Exploraci칩n gr치fica: diagrama de residuos standarizados y valores predichos.

OPCI칍N 2: Con el Score Test for Non-Constant Error Variance, tambi칠n llamado Test Breusch Pagan. Eval칰a si la varianza del error cambia con el nivel de la variable respuesta (valores ajustados) o con una combinaci칩n lineal de predictores.

**C칩digo e interpretaci칩n**

Si usamos el gr치fico

```{r}
plot(modelo1, 3)
```

En el Gr치fico la l칤nea roja debe seguir una tendencia horizontal, esto representar칤a que la distribuci칩n de los puntos son uniformes. Al ver nuestro gr치fico nos damos cuenta que la l칤nea roja va hacia arriba, lo cual nos dice que el gr치fico no es concluyente a칰n. Vamos al test.

Si usamos el test de BP:

```{r message=FALSE, warning=FALSE}
library(lmtest)
bptest(modelo1)
```

H0: El modelo es homoced치stico Ha: El modelo es heteroced치stico

Si el pvalor es menor a 0.05 entonces el modelo es heteroced치stico (problema!). Esta vez estamos frente a un modelo homoced치stico

### 4. Ausencia de multicolinealidad (el problema es la presencia de multicolinealidad)

**Descripci칩n**

Se aplica en la regresi칩n lineal M칔LTIPLE. Significa que las variables explicativas est치n relacionadas linealmente entre s칤. La multicolinealidad hace que los coeficientes del modelo se vuelvan inestables, es decir, oscilar치n violentamente ante cambios m칤nimos en las variables de insumo. Esto entender칤a que existe una relaci칩n fuerte entre variables independientes, por lo tanto podr칤a darnos un modelo inestable.

**C칩mo detectarlo**

Con el Factor de Inflaci칩n de Varianza (VIF). los factores de inflaci칩n de varianza deben de ser menores de 5. De acuerdo a nuestros resultados no encontramos multicolinealidad.

**C칩digo e interpretaci칩n**

```{r}
library(DescTools)
VIF(modelo1)
```

Valores \> 5 indican presencia de multicolinealidad.

### 5.- Independencia de residuos (el problema es que existe autocorrelaci칩n en los residuos)

**Descripci칩n**

Si los errores residuales **no son independientes**, es probable que demuestren alg칰n tipo de patr칩n (que no siempre es obvio a simple vista).

**C칩mo detectarlo**

Se puede realizar el Test de Durbin Watson (que mide el la presencia de correlaci칩n de cada error residual con el error residual "anterior")

**C칩digo e interpretaci칩n**

```{r message=FALSE, warning=FALSE}
#Default
library(car)
durbinWatsonTest(modelo1)
```

Durbin Watson: Las hip칩tesis son: H0: Los residuos son independientes Ha: Los residuos no son independientes Si el pvalor es menor a 0.05 entonces los residuos no son independientes o tambi칠n se podr칤a decir que est치n **autocorrelacionados** (problema!). En este caso tenemos un p value de 0.518, mayor a 0.05, el cual nos indica que no nos encontramos frente a un caso de autocorrelaci칩n.

**Modelo 2** 쮼s posible mejorar mi modelo1? Esta vez, realizamos una regresi칩n sin nuestra var20.

```{r}
modelo2 <- lm(casos_100k~ var3+var5, competitividad)
summary(modelo2)
```

Seguimos nuestro flujograma para evaluar el modelo:

1.  Nos preguntamos si el modelo es v치lido:

-   Si el p-value es menor a 0.05 significa que rechazamos la hip칩tesis nula, lo cual probar칤a que nuestro modelo s칤 funciona. -Al tener un p-value de 2.62e-05 nuestro modelo s칤 funciona.

2.  쯈u칠 tanto explica el modelo? -Revisamos el R cuadrado ajustado que va de 0 a 1 (0% a 100%) -En este caso mis variables (en conjunto) explican el 61.7% de la variabilidad de mi dependiente, esto es bueno, pero quiz치 podr칤a ser mejor.
3.  쯃as variables independientes aportan al modelo? -Nos enfocamos en el p-value de cada independiente -corroboramos que estas rechazen la hip칩tesis nula, es decir que sean menores que 0.05.

Conclusiones preliminares: el modelo s칤 pasa la evaluaci칩n; mis variables siguen aportando al modelo, mi modelo es v치lido al tener un p value de 2.62e-05; sin embargo, al sacar la variable var20 nos damos cuenta que mi modelo2 explica menos que mi modelo1. Por lo tanto, solo al evaluar mi modelo2, a pesar de que es un modelo v치lido, optar칤a por mantener mi modelo1. Ojo, solo bas치ndome en esta primera evaluaci칩n del modelo. Una decisi칩n m치s fina ser칤a al realizar mis pruebas de supuestos completa.
