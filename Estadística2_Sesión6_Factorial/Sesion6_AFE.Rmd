---
title: "SESI√ìN 06 - An√°lisis Factorial Exploratorio (AFE)"
author: "Curso: Estad√≠stica para el an√°lisis pol√≠tico 2"
date: "Ciclo 2023-1"
output:
  prettydoc::html_pretty:
    theme: cayman
    highlight: github
editor_options: 
  markdown: 
    wrap: 72
---

## FACULTAD DE CIENCIAS SOCIALES - PUCP <br>

#### Jefe de Pr√°ctica: Lizette Crisp√≠n üë©‚Äçüíª <br>

El An√°lisis Factorial Exploratorio (AFE) es una t√©cnica estad√≠stica que
permite explorar con mayor precisi√≥n las dimensiones subyacentes,
constructos o variables latentes de las variables observadas, es decir,
las que observa y mide el investigador.

Hacemos analisis factorial para reducir las variables en otras variables
resumen. Es decir, queremos saber si las nuevas variables tienen un
nombre, al cual se le denomina t√©cnicamente variable latente. En esta
sesi√≥n exploraremos la data a ver qu√© emerge.

```{r message=FALSE, warning=FALSE}
library(foreign)
data=read.spss("enaho_2020.sav",use.value.labels=TRUE, max.value.labels=TRUE, to.data.frame=TRUE)
```

## Tema de la clase

Vamos a ver si podemos crear una variable *latente de confianza* en las
instituciones *(del P1\$01 (col 11) al P1\$31 (col 31)).*

Vamos a tomar 11 variables observables de la base de datos de enaho, que
es justo la bater√≠a de preguntas que les mostr√© en el cuestionario.

## Preparamos las variables

Confianza en las instituciones

### Subset de las variables que usaremos

```{r echo = T, results = 'hide',  fig.show='hide', message=FALSE, warning=FALSE}
confianza=data[,c(11:22)]
#En caso quieran mencionar el nombre de la variable pueden usar el comando select() del paquete dplyr.
```

```{r echo = T, results = 'hide',  fig.show='hide', message=FALSE, warning=FALSE}
confianza[confianza== 5] <- NA
```

Eliminamos los datos perdidos √∫nicamente de la selecci√≥n de variables.

```{r echo = T, results = 'hide',  fig.show='hide'}
confianza=na.omit(confianza)
```

Etiquetamos las variables seleccionadas de acuerdo al nombre

```{r echo = T, results = 'hide',  fig.show='hide', message=FALSE, warning=FALSE}
names(confianza)=c("JNE","ONPE","RENIEC","Mun.Prov","Mun.Dist","PNP","FFAA","Gob.Reg","P.Judicial","MINEDU","Def.Pueblo","Congreso")
```

## **PASO 1:** Calcular la matriz de correlaci√≥n

Tenemos diferentes maneras de crear la matriz de correlaci√≥n.

Al tener una variable que mide confianza desde nada a mucha confianza,
la denominamos como ordinal, y por lo tanto,tendremos que ejecutar la
correlaci√≥n polic√≥rica.

```{r echo = T, results = 'hide',  fig.show='hide', message=FALSE, warning=FALSE}
#install.packages("polycor")
library(polycor)
library(psych)
poly_cor = polychoric(confianza)
poly_cor
```

Creamos un objeto con la matriz de correlaciones

```{r echo = T, results = 'hide',  fig.show='hide', message=FALSE, warning=FALSE}
corMatrix=poly_cor$rho 
```

```{r echo = T, results = 'hide',  fig.show='hide', message=FALSE, warning=FALSE}
cor.plot(corMatrix,
          numbers=T, #Se muestren los numeros de las correlaciones
          upper=F, #Que aparezca la segunda parte
          main= "Matriz de correlaciones",#Titulo
          show.legend=T)#Mostrar leyenda
```

## **PASO 2:** Verificando que los datos se puedan factorizar

‚ùó La prueba de KMO nos permite determinar si se puede factorizar o no.

Lo que hace es eliminar la influencia o la informaci√≥n que realmente no
aporta en la relaci√≥n con las variables observables, para as√≠ ver la
correlaci√≥n real, a este proceso se le denomina correlaci√≥n parcial.

Lo que buscamos es que la correlaci√≥n parcial sea mayor a 0.5

Se solicita un valor de al menos 0.5, a partir del 0.8 ya es excelente.

```{r echo = T, results = 'hide',  fig.show='hide', message=FALSE, warning=FALSE}
library(psych)
psych::KMO(confianza) 
```

Lo que tenemos que ver es el overall MSA, este valor de preferencia
tiene que ser mayor a 0.5, queremos que salga m√°s cercano a 1.

## **PASO 3:** Verificar si la matriz de correlaciones es adecuada

Verificar si la matriz de correlaciones es adecuada.

-   Test de Bartlett:

```{r,echo=FALSE, out.width="20%", fig.align="center", message=FALSE, warning=FALSE}
knitr::include_graphics("BARTLETT.png") 
```

Otro manera de poder determinar si podemos realizar o no el an√°lisis
factorial, es mediante el test de bartlett, que nos permite indicar si
la matriz de correlaciones que henmos obsrvado en el primer paso se
parece o no a una matriz de identidad.

-   Que es la matriz de identidad?

Es una matriz donde solo se cuenta con los valores de 1 en la diagonal y
en los dem√°s valores es 0, es decir, que la unica correlaci√≥n existente
es entre las mismas variables.

Entonces, lo que esperamos es que la matriz de correlaci√≥n sea diferente
a la matriz de identidad, para concluir que s√≠ hay correlaci√≥n.

```{r echo = T, results = 'hide',  fig.show='hide', message=FALSE, warning=FALSE}
cortest.bartlett(corMatrix,n=nrow(confianza))$p.value>0.05#Menor a 0.05 saldr√° FALSE, mayor a 0.05 saldra TRUE
```

Este es una prueba de hip√≥tesis donde H0: La matriz de correlacion es
una matriz identidad

Entonces buscamos que se rechace la hip√≥tesis nula para as√≠ poder
determinar que la matriz de correlaci√≥n no se prece una matriz de
identidad

## **PASO 4:** Determinar cu√°ntos factores o variables latentes puede redimensionar la data

#### ‚û°Ô∏è **Opci√≥n 1: Gr√°fico de sedimentaci√≥n**

Luego de haber determinado si podemos realizar el an√°lisis factorial,
pasaremos al paso de calcular el n√∫mero de factores o de variables
latentes podemos obtener.

Esto lo podemos ver con 2 maneras,

Mediante el gr√°fico de sedimentaci√≥n. En este gr√°fico lo que veremos es
en donde se presenta la mayor ca√≠da para determinar el n√∫mero de
factores.

Donde est√° el codo las X's que est√°n encima de la l√≠nea roja

```{r echo = T, results = 'hide',  fig.show='hide', message=FALSE, warning=FALSE}
fa.parallel(corMatrix, fm="pa", fa="fa", main = "Scree Plot")
```

El eje X vendr√≠a a ser lo factores que se podr√≠an dividir y el eje Y son
los autovalores

#### ‚û°Ô∏è **Opci√≥n 2: Eigen values - Autovalores**

Los autovalores que superan 1 son los factores que podr√≠amos realizar.

```{r echo = T, results = 'hide',  fig.show='hide', message=FALSE, warning=FALSE}
eigenf = eigen(cor(confianza, use="complete"))
eigenf$values
```

## **PASO 5:** Solicitamos el n√∫mero de componentes.

Aplicamos la redimensi√≥n

En esta parte, aplicamos los componentes principales.

```{r echo = T, results = 'hide',  fig.show='hide', message=FALSE, warning=FALSE}
#install.packages("GPArotation")
library(GPArotation)
factorial = fa(confianza,nfactors= 3 ,rotate = "varimax",fm="minres")
factorial
```

Diagramamos üìä

```{r echo = T, results = 'hide',  fig.show='hide', message=FALSE, warning=FALSE}
fa.diagram(factorial)
```

¬øQue variables componen cada uno de mis factores?

```{r echo = T, results = 'hide',  fig.show='hide', message=FALSE, warning=FALSE}
print(factorial$loadings,cutoff = 0.4)
```

1.Ver qu√© variables tiene cada componente

2.Ver la carga, que tanto aporta cada variable al componente.

3.Proportion Var y Cumulative Var

## **PASO 6:** Evaluamos el An√°lisis Factorial Exploratorio solicitado

-   ¬øQu√© variables aportaron mas a los factores?

```{r echo = T, results = 'hide',  fig.show='hide', message=FALSE, warning=FALSE}
sort(factorial$communality)
```

-   ¬øQu√© variables contribuyen a mas de un factor?

```{r echo = T, results = 'hide',  fig.show='hide', message=FALSE, warning=FALSE}
sort(factorial$complexity)
```

-   ¬øQu√© variables tiene un componente "√∫nico" m√°s grande?

```{r echo = T, results = 'hide',  fig.show='hide', message=FALSE, warning=FALSE}
sort(factorial$uniquenesses)
```

Que tanto componente unico entre las variales, tiene menor cantidad de
informaci√≥n en com√∫n (o sea varianza com√∫n)

## **PASO 7:** Guardamos los componentes como nuevas variables

Podemos crear un data set con s√≥lo los factores creados

```{r echo = T, results = 'hide',  fig.show='hide', message=FALSE, warning=FALSE}
factorial_casos<-as.data.frame(factorial$scores)
head(factorial_casos)
summary(factorial_casos)
```

Agregamos a la subdata

```{r echo = T, results = 'hide',  fig.show='hide', message=FALSE, warning=FALSE}
confianza$confins1<- factorial_casos$MR1
confianza$confins2<- factorial_casos$MR2
confianza$confins3<- factorial_casos$MR3
```

-   Primer factor:Poderes del Estado
-   Segundo factor: Organismos electorales (confins2)
-   Tercer factor:organismos regionales

## **PASO 8:** Estandarizamos a una escala de 100

```{r echo = T, results = 'hide',  fig.show='hide', message=FALSE, warning=FALSE}
#install.packages("BBmisc")
library(BBmisc)
confianza$confins1 = normalize(confianza$confins1, 
                                        method = "range", 
                                        margin=2, # by column
                                        range = c(0, 100))
confianza$confins2 = normalize(confianza$confins2, 
                                        method = "range", 
                                        margin=2, # by column
                                        range = c(0, 100))
confianza$confins3 = normalize(confianza$confins3, 
                                        method = "range", 
                                        margin=2, # by column
                                        range = c(0, 100))

```

Vemos resultados de cada factor

```{r echo = T, results = 'hide',  fig.show='hide', message=FALSE, warning=FALSE}
summary(confianza)
```
